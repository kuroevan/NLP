{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MSDS 7337 - Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### by Evangelos GIakoumakis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import required libraries to perform required tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division  # Python 2 users only\n",
    "import nltk, re, pprint\n",
    "from nltk import word_tokenize\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out system information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System information:\n",
      "Windows-10-10.0.17134\n",
      "('Python', '2.7.15 |Anaconda, Inc.| (default, May  1 2018, 18:37:09) [MSC v.1500 64 bit (AMD64)]')\n"
     ]
    }
   ],
   "source": [
    "print (\"System information:\")\n",
    "import platform; \n",
    "print(platform.platform())\n",
    "import sys\n",
    "print(\"Python\", sys.version)\n",
    "max_range = 101"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to download texts given a URL address and place in a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_fetcher(url):\n",
    "\n",
    "    response = urllib.urlopen(url)\n",
    "    raw = response.read().decode('utf8')\n",
    "    if len(raw) > 0:\n",
    "        return raw\n",
    "    else:\n",
    "        return \"Failed\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of URL's containing the address of 100 books in txt format from the gutenberg website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list = list(range(0, max_range)) \n",
    "\n",
    "url_list[0] = \"http://www.gutenberg.org/cache/epub/7841/pg7841.txt\"\n",
    "url_list[1] = \"http://www.gutenberg.org/cache/epub/5742/pg5742.txt\"\n",
    "url_list[2] = \"http://www.gutenberg.org/cache/epub/13539/pg13539.txt\"\n",
    "url_list[3] = \"http://www.gutenberg.org/cache/epub/7425/pg7425.txt\"\n",
    "url_list[4] = \"http://www.gutenberg.org/cache/epub/16046/pg16046.txt\"\n",
    "url_list[5] = \"http://www.gutenberg.org/cache/epub/22420/pg22420.txt\"\n",
    "url_list[6] = \"http://www.gutenberg.org/files/23424/23424-0.txt\"\n",
    "url_list[7] = \"http://www.gutenberg.org/cache/epub/18217/pg18217.txt\"\n",
    "url_list[8] = \"http://www.gutenberg.org/cache/epub/24053/pg24053.txt\"\n",
    "url_list[9] = \"http://www.gutenberg.org/cache/epub/24644/pg24644.txt\"\n",
    "url_list[10] = \"http://www.gutenberg.org/cache/epub/24703/pg24703.txt\"\n",
    "url_list[11] = \"http://www.gutenberg.org/cache/epub/15659/pg15659.txt\"\n",
    "url_list[12] = \"http://www.gutenberg.org/cache/epub/15170/pg15170.txt\"\n",
    "url_list[13] = \"http://www.gutenberg.org/cache/epub/10811/pg10811.txt\"\n",
    "url_list[14] = \"http://www.gutenberg.org/cache/epub/9106/pg9106.txt\"\n",
    "url_list[15] = \"http://www.gutenberg.org/cache/epub/19721/pg19721.txt\"\n",
    "url_list[16] = \"http://www.gutenberg.org/cache/epub/14640/pg14640.txt\"\n",
    "url_list[17] = \"http://www.gutenberg.org/cache/epub/14668/pg14668.txt\"\n",
    "url_list[18] = \"http://www.gutenberg.org/cache/epub/14766/pg14766.txt\"\n",
    "url_list[19] = \"http://www.gutenberg.org/cache/epub/14880/pg14880.txt\"\n",
    "url_list[20] = \"http://www.gutenberg.org/cache/epub/15040/pg15040.txt\"\n",
    "url_list[21] = \"http://www.gutenberg.org/cache/epub/16751/pg16751.txt\"\n",
    "url_list[22] = \"http://www.gutenberg.org/files/13853/13853-0.txt\"\n",
    "url_list[23] = \"http://www.gutenberg.org/cache/epub/15825/pg15825.txt\"\n",
    "url_list[24] = \"http://www.gutenberg.org/cache/epub/18561/pg18561.txt\"\n",
    "url_list[25] = \"http://www.gutenberg.org/cache/epub/18702/pg18702.txt\"\n",
    "url_list[26] = \"http://www.gutenberg.org/cache/epub/19923/pg19923.txt\"\n",
    "url_list[27] = \"http://www.gutenberg.org/files/22795/22795-0.txt\"\n",
    "url_list[28] = \"http://www.gutenberg.org/cache/epub/16936/pg16936.txt\"\n",
    "url_list[29] = \"http://www.gutenberg.org/cache/epub/9078/pg9078.txt\"\n",
    "url_list[30] = \"http://www.gutenberg.org/cache/epub/6685/pg6685.txt\"\n",
    "url_list[31] = \"http://www.gutenberg.org/cache/epub/18909/pg18909.txt\"\n",
    "url_list[32] = \"http://www.gutenberg.org/cache/epub/19469/pg19469.txt\"\n",
    "url_list[33] = \"http://www.gutenberg.org/cache/epub/11023/pg11023.txt\"\n",
    "url_list[34] = \"http://www.gutenberg.org/cache/epub/15353/pg15353.txt\"\n",
    "url_list[35] = \"http://www.gutenberg.org/cache/epub/22065/pg22065.txt\"\n",
    "url_list[36] = \"http://www.gutenberg.org/cache/epub/24072/pg24072.txt\"\n",
    "url_list[37] = \"http://www.gutenberg.org/cache/epub/15626/pg15626.txt\"\n",
    "url_list[38] = \"http://www.gutenberg.org/files/23424/23424-0.txt\"\n",
    "url_list[39] = \"http://www.gutenberg.org/cache/epub/15577/pg15577.txt\"\n",
    "url_list[40] = \"http://www.gutenberg.org/files/18274/18274-0.txt\"\n",
    "url_list[41] = \"http://www.gutenberg.org/cache/epub/19381/pg19381.txt\"\n",
    "url_list[42] = \"http://www.gutenberg.org/cache/epub/13347/pg13347.txt\"\n",
    "url_list[43] = \"http://www.gutenberg.org/files/21973/21973-0.txt\"\n",
    "url_list[44] = \"http://www.gutenberg.org/cache/epub/10737/pg10737.txt\"\n",
    "url_list[45] = \"http://www.gutenberg.org/cache/epub/21266/pg21266.txt\"\n",
    "url_list[46] = \"http://www.gutenberg.org/cache/epub/17365/pg17365.txt\"\n",
    "url_list[47] = \"http://www.gutenberg.org/cache/epub/2284/pg2284.txt\"\n",
    "url_list[48] = \"http://www.gutenberg.org/cache/epub/3031/pg3031.txt\"\n",
    "url_list[49] = \"http://www.gutenberg.org/cache/epub/23667/pg23667.txt\"\n",
    "url_list[50] = \"http://www.gutenberg.org/files/15950/15950-0.txt\"\n",
    "url_list[51] = \"http://www.gutenberg.org/files/2441/2441-0.txt\"\n",
    "url_list[52] = \"http://www.gutenberg.org/cache/epub/17185/pg17185.txt\"\n",
    "url_list[53] = \"http://www.gutenberg.org/cache/epub/10834/pg10834.txt\"\n",
    "url_list[54] = \"http://www.gutenberg.org/cache/epub/18790/pg18790.txt\"\n",
    "url_list[55] = \"http://www.gutenberg.org/cache/epub/16140/pg16140.txt\"\n",
    "url_list[56] = \"http://www.gutenberg.org/cache/epub/21948/pg21948.txt\"\n",
    "url_list[57] = \"http://www.gutenberg.org/cache/epub/10726/pg10726.txt\"\n",
    "url_list[58] = \"http://www.gutenberg.org/cache/epub/18767/pg18767.txt\"\n",
    "url_list[59] = \"http://www.gutenberg.org/cache/epub/22408/pg22408.txt\"\n",
    "url_list[60] = \"http://www.gutenberg.org/cache/epub/14759/pg14759.txt\"\n",
    "url_list[61] = \"http://www.gutenberg.org/cache/epub/23576/pg23576.txt\"\n",
    "url_list[62] = \"http://www.gutenberg.org/cache/epub/24263/pg24263.txt\"\n",
    "url_list[63] = \"http://www.gutenberg.org/files/24222/24222-0.txt\"\n",
    "url_list[64] = \"http://www.gutenberg.org/cache/epub/23941/pg23941.txt\"\n",
    "url_list[65] = \"http://www.gutenberg.org/cache/epub/18525/pg18525.txt\"\n",
    "url_list[66] = \"http://www.gutenberg.org/cache/epub/24409/pg24409.txt\"\n",
    "url_list[67] = \"http://www.gutenberg.org/cache/epub/24852/pg24852.txt\"\n",
    "url_list[68] = \"http://www.gutenberg.org/cache/epub/24598/pg24598.txt\"\n",
    "url_list[69] = \"http://www.gutenberg.org/cache/epub/11313/pg11313.txt\"\n",
    "url_list[70] = \"http://www.gutenberg.org/cache/epub/18561/pg18561.txt\"\n",
    "url_list[71] = \"http://www.gutenberg.org/cache/epub/16667/pg16667.txt\"\n",
    "url_list[72] = \"http://www.gutenberg.org/cache/epub/20107/pg20107.txt\"\n",
    "url_list[73] = \"http://www.gutenberg.org/cache/epub/22727/pg22727.txt\"\n",
    "url_list[74] = \"http://www.gutenberg.org/cache/epub/9995/pg9995.txt\"\n",
    "url_list[75] = \"http://www.gutenberg.org/cache/epub/22911/pg22911.txt\"\n",
    "url_list[76] = \"http://www.gutenberg.org/cache/epub/24676/pg24676.txt\"\n",
    "url_list[77] = \"http://www.gutenberg.org/cache/epub/24884/pg24884.txt\"\n",
    "url_list[78] = \"http://www.gutenberg.org/files/21783/21783-0.txt\"\n",
    "url_list[79] = \"http://www.gutenberg.org/files/17160/17160-0.txt\"\n",
    "url_list[80] = \"http://www.gutenberg.org/cache/epub/16728/pg16728.txt\"\n",
    "url_list[81] = \"http://www.gutenberg.org/cache/epub/16379/pg16379.txt\"\n",
    "url_list[82] = \"http://www.gutenberg.org/cache/epub/20522/pg20522.txt\"\n",
    "url_list[83] = \"http://www.gutenberg.org/cache/epub/20698/pg20698.txt\"\n",
    "url_list[84] = \"http://www.gutenberg.org/cache/epub/19423/pg19423.txt\"\n",
    "url_list[85] = \"http://www.gutenberg.org/cache/epub/7803/pg7803.txt\"\n",
    "url_list[86] = \"http://www.gutenberg.org/cache/epub/24858/pg24858.txt\"\n",
    "url_list[87] = \"http://www.gutenberg.org/cache/epub/22245/pg22245.txt\"\n",
    "url_list[88] = \"http://www.gutenberg.org/cache/epub/23560/pg23560.txt\"\n",
    "url_list[89] = \"http://www.gutenberg.org/cache/epub/23728/pg23728.txt\"\n",
    "url_list[90] = \"http://www.gutenberg.org/cache/epub/22425/pg22425.txt\"\n",
    "url_list[91] = \"http://www.gutenberg.org/cache/epub/22600/pg22600.txt\"\n",
    "url_list[92] = \"http://www.gutenberg.org/cache/epub/22766/pg22766.txt\"\n",
    "url_list[93] = \"http://www.gutenberg.org/files/22917/22917-0.txt\"\n",
    "url_list[94] = \"http://www.gutenberg.org/cache/epub/12655/pg12655.txt\"\n",
    "url_list[95] = \"http://www.gutenberg.org/cache/epub/22925/pg22925.txt\"\n",
    "url_list[96] = \"http://www.gutenberg.org/files/23395/23395-0.txt\"\n",
    "url_list[97] = \"http://www.gutenberg.org/cache/epub/24030/pg24030.txt\"\n",
    "url_list[98] = \"http://www.gutenberg.org/cache/epub/24125/pg24125.txt\"\n",
    "url_list[99] = \"http://www.gutenberg.org/cache/epub/24656/pg24656.txt\"\n",
    "url_list[100] = \"http://www.gutenberg.org/cache/epub/20557/pg20557.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download all 100 books and place in a list. Then print out their titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book Title List:\n",
      "﻿The Project Gutenberg EBook of A Primary Reader, by E. Louise Smythe\n",
      "﻿The Project Gutenberg EBook of The Bird-Woman of the Lewis and Clark\n",
      "﻿The Project Gutenberg EBook of Dr. Scudder's Tales for Little Readers\n",
      "﻿The Project Gutenberg EBook of The Louisa Alcott Reader, by Louisa M.\n",
      "﻿The Project Gutenberg EBook of Boy Blue and His Friends\n",
      "by Etta Aust\n",
      "﻿The Project Gutenberg EBook of The Book of Nature Myths, by Florence \n",
      "﻿The Project Gutenberg EBook of The Flag of My Country. Shikéyah Bidah\n",
      "﻿Project Gutenberg's Chambers's Elementary Science Readers, by Various\n",
      "﻿The Project Gutenberg EBook of The Little Lame Prince, by \n",
      "Dinah Mar\n",
      "﻿The Project Gutenberg EBook of Harry's Ladder to Learning, by Anonymo\n",
      "﻿The Project Gutenberg EBook of Little Present, by Unknown\n",
      "\n",
      "This eBo\n",
      "﻿The Project Gutenberg EBook of The Beacon Second Reader, by James H. \n",
      "﻿The Project Gutenberg EBook of The Child's World\n",
      "by Hetty Browne, Sa\n",
      "﻿The Project Gutenberg EBook of De La Salle Fifth Reader\n",
      "by Brothers \n",
      "﻿The Project Gutenberg EBook of The Elson Readers, Book 5\n",
      "by William \n",
      "﻿The Project Gutenberg EBook of The Literary World Seventh Reader, by \n",
      "﻿The Project Gutenberg EBook of McGuffey's First Eclectic Reader, Revi\n",
      "﻿The Project Gutenberg EBook of McGuffey's Second Eclectic Reader\n",
      "by \n",
      "﻿The Project Gutenberg EBook of McGuffey's Third Eclectic Reader\n",
      "by W\n",
      "﻿The Project Gutenberg EBook of McGuffey's Fourth Eclectic Reader\n",
      "by \n",
      "﻿The Project Gutenberg EBook of McGuffey's Fifth Eclectic Reader\n",
      "by W\n",
      "﻿The Project Gutenberg EBook of McGuffey's Sixth Eclectic Reader\n",
      "by W\n",
      "﻿Project Gutenberg's New National First Reader, by Charles J. Barnes, \n",
      "﻿The Project Gutenberg eBook, New National Fourth Reader, by Charles J\n",
      "﻿Project Gutenberg's The Ontario Readers, by Ontario Ministry of Educa\n",
      "﻿The Project Gutenberg eBook, The Ontario Readers: Fourth Book, by Var\n",
      "﻿The Project Gutenberg EBook of The Ontario Readers: The High School\n",
      "\n",
      "﻿The Project Gutenberg EBook of The Ontario High School Reader, by A.E\n",
      "﻿The Project Gutenberg EBook of Parker's Second Reader, by Richard G. \n",
      "﻿Project Gutenberg's Sanders' Union Fourth Reader, by Charles W. Sande\n",
      "﻿The Project Gutenberg EBook of Story Hour Readers  Book Three, by \n",
      "\n",
      "﻿The Project Gutenberg EBook of Poems Teachers Ask For, by Various\n",
      "\n",
      "\n",
      "﻿The Project Gutenberg eBook, Poems Teachers Ask For, Book Two, by Var\n",
      "﻿The Project Gutenberg eBook, Gems of Poetry, for Girls and Boys, by U\n",
      "﻿The Project Gutenberg EBook of A First Spanish Reader\n",
      "by Erwin W. Ro\n",
      "﻿Project Gutenberg's An Elementary Spanish Reader, by Earl Stanley Har\n",
      "﻿The Project Gutenberg eBook, First Italian Readings, by Various, Edit\n",
      "﻿The Project Gutenberg EBook of Contes et historiettes à l'usage des j\n",
      "﻿The Project Gutenberg EBook of The Flag of My Country. Shikéyah Bidah\n",
      "﻿Project Gutenberg's A History of the McGuffey Readers, by Henry H. Va\n",
      "﻿The Project Gutenberg EBook of A Book of Natural History, by Various\n",
      "﻿Project Gutenberg's Among the Farmyard People, by Clara Dillingham Pi\n",
      "﻿The Project Gutenberg EBook of Wildflowers of the Farm, by Arthur Owe\n",
      "﻿The Project Gutenberg EBook of Anecdotes of the Habits and Instinct o\n",
      "﻿The Project Gutenberg EBook of Book about Animals, by Rufus Merrill\n",
      "\n",
      "﻿The Project Gutenberg EBook of Bird Day; How to prepare for it, by \n",
      "\n",
      "﻿The Project Gutenberg EBook of Child's Book of Water Birds, by Anonym\n",
      "﻿The Project Gutenberg EBook of Animal Heroes, by Ernest Thompson Seto\n",
      "﻿Project Gutenberg's Wild Animals I Have  Known, by Ernest Thompson Se\n",
      "﻿The Project Gutenberg EBook of Woodland Tales, by Ernest Seton-Thomps\n",
      "﻿The Project Gutenberg EBook of Wilderness Ways, by William J Long\n",
      "\n",
      "\n",
      "﻿The Project Gutenberg EBook of The Burgess Animal Book for Children, \n",
      "﻿The Project Gutenberg EBook of Stories about the Instinct of Animals,\n",
      "﻿The Project Gutenberg eBook, The History of Insects, by Unknown\n",
      "\n",
      "\n",
      "\n",
      "﻿The Project Gutenberg EBook of The Insect Folk, by Margaret Warner Mo\n",
      "﻿Project Gutenberg's The Curious Book of Birds, by Abbie Farwell Brown\n",
      "﻿The Project Gutenberg eBook, Little Busybodies, by Jeanette Augustus \n",
      "﻿The Project Gutenberg eBook, Outlines of Lessons in Botany, Part I; F\n",
      "﻿The Project Gutenberg eBook, Stories about Animals: with Pictures to\n",
      "﻿Project Gutenberg's Chatterbox Stories of Natural History, by Anonymo\n",
      "﻿The Project Gutenberg EBook of Camping For Boys, by H.W. Gibson\n",
      "\n",
      "Th\n",
      "﻿Project Gutenberg's Quadrupeds, What They Are and Where Found, by May\n",
      "﻿Project Gutenberg's A Hundred Anecdotes of Animals, by Percy J. Billi\n",
      "﻿The Project Gutenberg EBook of The Story of Eclipses, by George Chamb\n",
      "﻿The Project Gutenberg EBook of Country Walks of a Naturalist with His\n",
      "﻿Project Gutenberg's On the Trail, by Lina Beard and Adelia Belle Bear\n",
      "﻿The Project Gutenberg EBook of Our Common Insects, by Alpheus Spring \n",
      "﻿Project Gutenberg's The Wonders of the Jungle, by Prince Sarath Ghosh\n",
      "﻿The Project Gutenberg EBook of A Modern History, From the Time of Lut\n",
      "﻿The Project Gutenberg EBook of A School History of the United States\n",
      "﻿Project Gutenberg's The Ontario Readers, by Ontario Ministry of Educa\n",
      "﻿Project Gutenberg's Young Folks' History of Rome, by Charlotte Mary Y\n",
      "﻿The Project Gutenberg eBook, Denmark, by M. Pearson Thomson, Illustra\n",
      "﻿The Project Gutenberg EBook of The Land of the Long Night, by Paul du\n",
      "﻿Project Gutenberg's A Little Journey to Puerto Rico, by Marian M. Geo\n",
      "﻿The Project Gutenberg EBook of Where We Live, by Emilie Van Beil Jaco\n",
      "﻿Project Gutenberg's Peeps at Many Lands: Norway, by A.F. Mockler-Ferr\n",
      "﻿The Project Gutenberg eBook, Commercial Geography, by Jacques W. Redw\n",
      "﻿The Project Gutenberg EBook of A Manual of Pronunciation, by Otis Ash\n",
      "﻿The Project Gutenberg EBook of Modern Prose And Poetry; For Secondary\n",
      "﻿The Project Gutenberg EBook of A Catechism of Familiar Things; Their\n",
      "﻿The Project Gutenberg EBook of Children's Classics in Dramatic Form\n",
      "\n",
      "﻿The Project Gutenberg EBook of The Story of the Mind, by James Mark B\n",
      "﻿The Project Gutenberg EBook of The Story of Glass, by Sara Ware Basse\n",
      "﻿The Project Gutenberg eBook, The Story of Porcelain, by Sara Ware Bas\n",
      "﻿The Project Gutenberg EBook of The Story of Sugar, by Sara Ware Basse\n",
      "﻿The Project Gutenberg EBook of The Story of Wool, by Sara Ware Basset\n",
      "﻿Project Gutenberg's Steve and the Steam Engine, by Sara Ware Bassett\n",
      "﻿The Project Gutenberg eBook, Carl and the Cotton Gin, by Sara Ware\n",
      "B\n",
      "﻿The Project Gutenberg EBook of Walter and the Wireless, by Sara Ware \n",
      "﻿The Project Gutenberg EBook of Stanford Achievement Test, Ed. 1922, b\n",
      "﻿The Project Gutenberg EBook of How to Write Clearly, by Edwin A. Abbo\n",
      "﻿The Project Gutenberg EBook of Electricity for Boys, by J. S. Zerbe\n",
      "\n",
      "﻿The Project Gutenberg EBook of Leçons de cosmographie, by Adrien Guil\n",
      "﻿Project Gutenberg's The Boy Mechanic: Volume 1, by Popular Mechanics\n",
      "﻿Project Gutenberg's The Story of Young Abraham Lincoln, by Wayne Whip\n",
      "﻿The Project Gutenberg EBook of Orthography, by Elmer W. Cavins\n",
      "\n",
      "Thi\n",
      "﻿The Project Gutenberg EBook of Stories From Livy, by Alfred Church\n",
      "\n",
      "﻿Project Gutenberg's A Little Book for A Little Cook, by L. P. Hubbard\n",
      "﻿The Project Gutenberg EBook of Ontario Teachers' Manuals: Household\n",
      "\n",
      "﻿The Project Gutenberg EBook of Ontario Teachers' Manuals: Household\n",
      "\n"
     ]
    }
   ],
   "source": [
    "book_list = list(range(0, max_range)) \n",
    "print (\"Book Title List:\")\n",
    "for count in range(max_range):\n",
    "    book_list[count] = text_fetcher(url_list[count])\n",
    "    print book_list[count][:70]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize downloaded books and place in a different list for further analysis. Print out first 10 tokens of each book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book Token List:\n",
      "[u'\\ufeffThe', u'Project', u'Gutenberg', u'EBook', u'of', u'A', u'Primary', u'Reader', u',', u'by']\n",
      "[u'\\ufeffThe', u'Project', u'Gutenberg', u'EBook', u'of', u'The', u'Bird-Woman', u'of', u'the', u'Lewis']\n",
      "[u'\\ufeffThe', u'Project', u'Gutenberg', u'EBook', u'of', u'Dr.', u'Scudder', u\"'s\", u'Tales', u'for']\n",
      "[u'\\ufeffThe', u'Project', u'Gutenberg', u'EBook', u'of', u'The', u'Louisa', u'Alcott', u'Reader', u',']\n",
      "[u'\\ufeffThe', u'Project', u'Gutenberg', u'EBook', u'of', u'Boy', u'Blue', u'and', u'His', u'Friends']\n",
      "[u'\\ufeffThe', u'Project', u'Gutenberg', u'EBook', u'of', u'The', u'Book', u'of', u'Nature', u'Myths']\n",
      "[u'\\ufeffThe', u'Project', u'Gutenberg', u'EBook', u'of', u'The', u'Flag', u'of', u'My', u'Country']\n",
      "[u'\\ufeffProject', u'Gutenberg', u\"'s\", u'Chambers', u\"'s\", u'Elementary', u'Science', u'Readers', u',', u'by']\n",
      "[u'\\ufeffThe', u'Project', u'Gutenberg', u'EBook', u'of', u'The', u'Little', u'Lame', u'Prince', u',']\n",
      "[u'\\ufeffThe', u'Project', u'Gutenberg', u'EBook', u'of', u'Harry', u\"'s\", u'Ladder', u'to', u'Learning']\n",
      "[u'\\ufeffThe', u'Project', u'Gutenberg', u'EBook', u'of', u'Little', u'Present', u',', u'by', u'Unknown']\n",
      "[u'\\ufeffThe', u'Project', u'Gutenberg', u'EBook', u'of', u'The', u'Beacon', u'Second', u'Reader', u',']\n",
      "[u'\\ufeffThe', u'Project', u'Gutenberg', u'EBook', u'of', u'The', u'Child', u\"'s\", u'World', u'by']\n",
      "[u'\\ufeffThe', u'Project', u'Gutenberg', u'EBook', u'of', u'De', u'La', u'Salle', u'Fifth', u'Reader']\n",
      "[u'\\ufeffThe', u'Project', u'Gutenberg', u'EBook', u'of', u'The', u'Elson', u'Readers', u',', u'Book']\n",
      "[u'\\ufeffThe', u'Project', u'Gutenberg', u'EBook', u'of', u'The', u'Literary', u'World', u'Seventh', u'Reader']\n",
      "[u'\\ufeffThe', u'Project', u'Gutenberg', u'EBook', u'of', u'McGuffey', u\"'s\", u'First', u'Eclectic', u'Reader']\n",
      "[u'\\ufeffThe', u'Project', u'Gutenberg', u'EBook', u'of', u'McGuffey', u\"'s\", u'Second', u'Eclectic', u'Reader']\n",
      "[u'\\ufeffThe', u'Project', u'Gutenberg', u'EBook', u'of', u'McGuffey', u\"'s\", u'Third', u'Eclectic', u'Reader']\n",
      "[u'\\ufeffThe', u'Project', u'Gutenberg', u'EBook', u'of', u'McGuffey', u\"'s\", u'Fourth', u'Eclectic', u'Reader']\n",
      "[u'\\ufeffThe', u'Project', u'Gutenberg', u'EBook', u'of', u'McGuffey', u\"'s\", u'Fifth', u'Eclectic', u'Reader']\n",
      "[u'\\ufeffThe', u'Project', u'Gutenberg', u'EBook', u'of', u'McGuffey', u\"'s\", u'Sixth', u'Eclectic', u'Reader']\n",
      "[u'\\ufeffProject', u'Gutenberg', u\"'s\", u'New', u'National', u'First', u'Reader', u',', u'by', u'Charles']\n",
      "[u'\\ufeffThe', u'Project', u'Gutenberg', u'eBook', u',', u'New', u'National', u'Fourth', u'Reader', u',']\n",
      "[u'\\ufeffProject', u'Gutenberg', u\"'s\", u'The', u'Ontario', u'Readers', u',', u'by', u'Ontario', u'Ministry']\n",
      "[u'\\ufeffThe', u'Project', u'Gutenberg', u'eBook', u',', u'The', u'Ontario', u'Readers', u':', u'Fourth']\n",
      "[u'\\ufeffThe', u'Project', u'Gutenberg', u'EBook', u'of', u'The', u'Ontario', u'Readers', u':', u'The']\n",
      "[u'\\ufeffThe', u'Project', u'Gutenberg', u'EBook', u'of', u'The', u'Ontario', u'High', u'School', u'Reader']\n",
      "[u'\\ufeffThe', u'Project', u'Gutenberg', u'EBook', u'of', u'Parker', u\"'s\", u'Second', u'Reader', u',']\n",
      "[u'\\ufeffProject', u'Gutenberg', u\"'s\", u'Sanders', u\"'\", u'Union', u'Fourth', u'Reader', u',', u'by']\n",
      "[u'\\ufeffThe', u'Project', u'Gutenberg', u'EBook', u'of', u'Story', u'Hour', u'Readers', u'\\x97', u'Book']\n",
      "[u'\\ufeffThe', u'Project', u'Gutenberg', u'EBook', u'of', u'Poems', u'Teachers', u'Ask', u'For', u',']\n",
      "[u'\\ufeffThe', u'Project', u'Gutenberg', u'eBook', u',', u'Poems', u'Teachers', u'Ask', u'For', u',']\n",
      "[u'\\ufeffThe', u'Project', u'Gutenberg', u'eBook', u',', u'Gems', u'of', u'Poetry', u',', u'for']\n",
      "[u'\\ufeffThe', u'Project', u'Gutenberg', u'EBook', u'of', u'A', u'First', u'Spanish', u'Reader', u'by']\n",
      "[u'\\ufeffProject', u'Gutenberg', u\"'s\", u'An', u'Elementary', u'Spanish', u'Reader', u',', u'by', u'Earl']\n",
      "[u'\\ufeffThe', u'Project', u'Gutenberg', u'eBook', u',', u'First', u'Italian', u'Readings', u',', u'by']\n",
      "[u'\\ufeffThe', u'Project', u'Gutenberg', u'EBook', u'of', u'Contes', u'et', u'historiettes', u'\\xe0', u\"l'usage\"]\n",
      "[u'\\ufeffThe', u'Project', u'Gutenberg', u'EBook', u'of', u'The', u'Flag', u'of', u'My', u'Country']\n",
      "[u'\\ufeffProject', u'Gutenberg', u\"'s\", u'A', u'History', u'of', u'the', u'McGuffey', u'Readers', u',']\n",
      "[u'\\ufeffThe', u'Project', u'Gutenberg', u'EBook', u'of', u'A', u'Book', u'of', u'Natural', u'History']\n",
      "[u'\\ufeffProject', u'Gutenberg', u\"'s\", u'Among', u'the', u'Farmyard', u'People', u',', u'by', u'Clara']\n",
      "[u'\\ufeffThe', u'Project', u'Gutenberg', u'EBook', u'of', u'Wildflowers', u'of', u'the', u'Farm', u',']\n",
      "[u'\\ufeffThe', u'Project', u'Gutenberg', u'EBook', u'of', u'Anecdotes', u'of', u'the', u'Habits', u'and']\n",
      "[u'\\ufeffThe', u'Project', u'Gutenberg', u'EBook', u'of', u'Book', u'about', u'Animals', u',', u'by']\n",
      "[u'\\ufeffThe', u'Project', u'Gutenberg', u'EBook', u'of', u'Bird', u'Day', u';', u'How', u'to']\n",
      "[u'\\ufeffThe', u'Project', u'Gutenberg', u'EBook', u'of', u'Child', u\"'s\", u'Book', u'of', u'Water']\n",
      "[u'\\ufeffThe', u'Project', u'Gutenberg', u'EBook', u'of', u'Animal', u'Heroes', u',', u'by', u'Ernest']\n",
      "[u'\\ufeffProject', u'Gutenberg', u\"'s\", u'Wild', u'Animals', u'I', u'Have', u'Known', u',', u'by']\n",
      "[u'\\ufeffThe', u'Project', u'Gutenberg', u'EBook', u'of', u'Woodland', u'Tales', u',', u'by', u'Ernest']\n",
      "[u'\\ufeffThe', u'Project', u'Gutenberg', u'EBook', u'of', u'Wilderness', u'Ways', u',', u'by', u'William']\n",
      "[u'\\ufeffThe', u'Project', u'Gutenberg', u'EBook', u'of', u'The', u'Burgess', u'Animal', u'Book', u'for']\n",
      "[u'\\ufeffThe', u'Project', u'Gutenberg', u'EBook', u'of', u'Stories', u'about', u'the', u'Instinct', u'of']\n",
      "[u'\\ufeffThe', u'Project', u'Gutenberg', u'eBook', u',', u'The', u'History', u'of', u'Insects', u',']\n",
      "[u'\\ufeffThe', u'Project', u'Gutenberg', u'EBook', u'of', u'The', u'Insect', u'Folk', u',', u'by']\n",
      "[u'\\ufeffProject', u'Gutenberg', u\"'s\", u'The', u'Curious', u'Book', u'of', u'Birds', u',', u'by']\n",
      "[u'\\ufeffThe', u'Project', u'Gutenberg', u'eBook', u',', u'Little', u'Busybodies', u',', u'by', u'Jeanette']\n",
      "[u'\\ufeffThe', u'Project', u'Gutenberg', u'eBook', u',', u'Outlines', u'of', u'Lessons', u'in', u'Botany']\n",
      "[u'\\ufeffThe', u'Project', u'Gutenberg', u'eBook', u',', u'Stories', u'about', u'Animals', u':', u'with']\n",
      "[u'\\ufeffProject', u'Gutenberg', u\"'s\", u'Chatterbox', u'Stories', u'of', u'Natural', u'History', u',', u'by']\n",
      "[u'\\ufeffThe', u'Project', u'Gutenberg', u'EBook', u'of', u'Camping', u'For', u'Boys', u',', u'by']\n",
      "[u'\\ufeffProject', u'Gutenberg', u\"'s\", u'Quadrupeds', u',', u'What', u'They', u'Are', u'and', u'Where']\n",
      "[u'\\ufeffProject', u'Gutenberg', u\"'s\", u'A', u'Hundred', u'Anecdotes', u'of', u'Animals', u',', u'by']\n",
      "[u'\\ufeffThe', u'Project', u'Gutenberg', u'EBook', u'of', u'The', u'Story', u'of', u'Eclipses', u',']\n",
      "[u'\\ufeffThe', u'Project', u'Gutenberg', u'EBook', u'of', u'Country', u'Walks', u'of', u'a', u'Naturalist']\n",
      "[u'\\ufeffProject', u'Gutenberg', u\"'s\", u'On', u'the', u'Trail', u',', u'by', u'Lina', u'Beard']\n",
      "[u'\\ufeffThe', u'Project', u'Gutenberg', u'EBook', u'of', u'Our', u'Common', u'Insects', u',', u'by']\n",
      "[u'\\ufeffProject', u'Gutenberg', u\"'s\", u'The', u'Wonders', u'of', u'the', u'Jungle', u',', u'by']\n",
      "[u'\\ufeffThe', u'Project', u'Gutenberg', u'EBook', u'of', u'A', u'Modern', u'History', u',', u'From']\n",
      "[u'\\ufeffThe', u'Project', u'Gutenberg', u'EBook', u'of', u'A', u'School', u'History', u'of', u'the']\n",
      "[u'\\ufeffProject', u'Gutenberg', u\"'s\", u'The', u'Ontario', u'Readers', u',', u'by', u'Ontario', u'Ministry']\n",
      "[u'\\ufeffProject', u'Gutenberg', u\"'s\", u'Young', u'Folks', u\"'\", u'History', u'of', u'Rome', u',']\n",
      "[u'\\ufeffThe', u'Project', u'Gutenberg', u'eBook', u',', u'Denmark', u',', u'by', u'M.', u'Pearson']\n",
      "[u'\\ufeffThe', u'Project', u'Gutenberg', u'EBook', u'of', u'The', u'Land', u'of', u'the', u'Long']\n",
      "[u'\\ufeffProject', u'Gutenberg', u\"'s\", u'A', u'Little', u'Journey', u'to', u'Puerto', u'Rico', u',']\n",
      "[u'\\ufeffThe', u'Project', u'Gutenberg', u'EBook', u'of', u'Where', u'We', u'Live', u',', u'by']\n",
      "[u'\\ufeffProject', u'Gutenberg', u\"'s\", u'Peeps', u'at', u'Many', u'Lands', u':', u'Norway', u',']\n",
      "[u'\\ufeffThe', u'Project', u'Gutenberg', u'eBook', u',', u'Commercial', u'Geography', u',', u'by', u'Jacques']\n",
      "[u'\\ufeffThe', u'Project', u'Gutenberg', u'EBook', u'of', u'A', u'Manual', u'of', u'Pronunciation', u',']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'\\ufeffThe', u'Project', u'Gutenberg', u'EBook', u'of', u'Modern', u'Prose', u'And', u'Poetry', u';']\n",
      "[u'\\ufeffThe', u'Project', u'Gutenberg', u'EBook', u'of', u'A', u'Catechism', u'of', u'Familiar', u'Things']\n",
      "[u'\\ufeffThe', u'Project', u'Gutenberg', u'EBook', u'of', u'Children', u\"'s\", u'Classics', u'in', u'Dramatic']\n",
      "[u'\\ufeffThe', u'Project', u'Gutenberg', u'EBook', u'of', u'The', u'Story', u'of', u'the', u'Mind']\n",
      "[u'\\ufeffThe', u'Project', u'Gutenberg', u'EBook', u'of', u'The', u'Story', u'of', u'Glass', u',']\n",
      "[u'\\ufeffThe', u'Project', u'Gutenberg', u'eBook', u',', u'The', u'Story', u'of', u'Porcelain', u',']\n",
      "[u'\\ufeffThe', u'Project', u'Gutenberg', u'EBook', u'of', u'The', u'Story', u'of', u'Sugar', u',']\n",
      "[u'\\ufeffThe', u'Project', u'Gutenberg', u'EBook', u'of', u'The', u'Story', u'of', u'Wool', u',']\n",
      "[u'\\ufeffProject', u'Gutenberg', u\"'s\", u'Steve', u'and', u'the', u'Steam', u'Engine', u',', u'by']\n",
      "[u'\\ufeffThe', u'Project', u'Gutenberg', u'eBook', u',', u'Carl', u'and', u'the', u'Cotton', u'Gin']\n",
      "[u'\\ufeffThe', u'Project', u'Gutenberg', u'EBook', u'of', u'Walter', u'and', u'the', u'Wireless', u',']\n",
      "[u'\\ufeffThe', u'Project', u'Gutenberg', u'EBook', u'of', u'Stanford', u'Achievement', u'Test', u',', u'Ed']\n",
      "[u'\\ufeffThe', u'Project', u'Gutenberg', u'EBook', u'of', u'How', u'to', u'Write', u'Clearly', u',']\n",
      "[u'\\ufeffThe', u'Project', u'Gutenberg', u'EBook', u'of', u'Electricity', u'for', u'Boys', u',', u'by']\n",
      "[u'\\ufeffThe', u'Project', u'Gutenberg', u'EBook', u'of', u'Le\\xe7ons', u'de', u'cosmographie', u',', u'by']\n",
      "[u'\\ufeffProject', u'Gutenberg', u\"'s\", u'The', u'Boy', u'Mechanic', u':', u'Volume', u'1', u',']\n",
      "[u'\\ufeffProject', u'Gutenberg', u\"'s\", u'The', u'Story', u'of', u'Young', u'Abraham', u'Lincoln', u',']\n",
      "[u'\\ufeffThe', u'Project', u'Gutenberg', u'EBook', u'of', u'Orthography', u',', u'by', u'Elmer', u'W.']\n",
      "[u'\\ufeffThe', u'Project', u'Gutenberg', u'EBook', u'of', u'Stories', u'From', u'Livy', u',', u'by']\n",
      "[u'\\ufeffProject', u'Gutenberg', u\"'s\", u'A', u'Little', u'Book', u'for', u'A', u'Little', u'Cook']\n",
      "[u'\\ufeffThe', u'Project', u'Gutenberg', u'EBook', u'of', u'Ontario', u'Teachers', u\"'\", u'Manuals', u':']\n",
      "[u'\\ufeffThe', u'Project', u'Gutenberg', u'EBook', u'of', u'Ontario', u'Teachers', u\"'\", u'Manuals', u':']\n"
     ]
    }
   ],
   "source": [
    "tokens_list = list(range(0, max_range)) \n",
    "print (\"Book Token List:\")\n",
    "for count in range(max_range):\n",
    "    tokens_list[count] = word_tokenize(book_list[count])\n",
    "    print tokens_list[count][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Vocabulary score function\n",
    "\n",
    "This function is used for scoring the vocabulary size of a text, and normalizing the score from 0 to 1. \n",
    "In order to calculate we first scan all available texts present in a list and find the one with the highest vocabulary number and store it to the variable max_length. We then use that variable dividing it with the equivalent number of the text that interests us to get the vocabulary score. By doing this division with the largest vocabulary number we ensure that our results will be normalized between 1 and 0, since we know that from the available books there is no one with a higher vocabulary length than max_length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "def vocab_scorer(text):  \n",
    "    try:\n",
    "        max_length = 0\n",
    "        score = 0.0\n",
    "        for count in range(max_range):\n",
    "            if count == 1:\n",
    "                max_length = len(set(tokens_list[count]))\n",
    "            if len(set(tokens_list[count])) > max_length:\n",
    "                max_length = len(set(tokens_list[count]))\n",
    "        print max_length\n",
    "        score = len(set(text)) / max_length\n",
    "        return score\n",
    "    except (TypeError):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the vocabulary score for all books in our list and print out the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size Score:\n",
      "Book_0 - 0.114671\n",
      "Book_1 - 0.126029\n",
      "Book_2 - 0.302526\n",
      "Book_3 - 0.299281\n",
      "Book_4 - 0.123131\n",
      "Book_5 - 0.176150\n",
      "Book_6 - 0.077761\n",
      "Book_7 - 0.211670\n",
      "Book_8 - 0.189014\n",
      "Book_9 - 0.183393\n",
      "Book_10 - 0.059045\n",
      "Book_11 - 0.263240\n",
      "Book_12 - 0.301020\n",
      "Book_13 - 0.533086\n",
      "Book_14 - 0.686464\n",
      "Book_15 - 0.756982\n",
      "Book_16 - 0.124464\n",
      "Book_17 - 0.233805\n",
      "Book_18 - 0.273207\n",
      "Book_19 - 0.599954\n",
      "Book_20 - 0.825530\n",
      "Book_21 - 1.000000\n",
      "Book_22 - 0.127361\n",
      "Book_23 - 0.607255\n",
      "Book_24 - 0.572372\n",
      "Book_25 - 0.699733\n",
      "Book_26 - 0.991077\n",
      "Book_27 - 0.691563\n",
      "Book_28 - 0.341928\n",
      "Book_29 - 0.991946\n",
      "Book_30 - 0.223143\n",
      "Book_31 - 0.705064\n",
      "Book_32 - 0.735717\n",
      "Book_33 - 0.100649\n",
      "Book_34 - 0.702225\n",
      "Book_35 - 0.419689\n",
      "Book_36 - 0.992873\n",
      "Book_37 - 0.344941\n",
      "Book_38 - 0.077761\n",
      "Book_39 - 0.241164\n",
      "Book_40 - 0.686812\n",
      "Book_41 - 0.224765\n",
      "Book_42 - 0.149322\n",
      "Book_43 - 0.659926\n",
      "Book_44 - 0.072720\n",
      "Book_45 - 0.277668\n",
      "Book_46 - 0.061653\n",
      "Book_47 - 0.458744\n",
      "Book_48 - 0.419747\n",
      "Book_49 - 0.393035\n",
      "Book_50 - 0.288678\n",
      "Book_51 - 0.319156\n",
      "Book_52 - 0.339205\n",
      "Book_53 - 0.103372\n",
      "Book_54 - 0.259822\n",
      "Book_55 - 0.310349\n",
      "Book_56 - 0.260517\n",
      "Book_57 - 0.257040\n",
      "Book_58 - 0.402770\n",
      "Book_59 - 0.236760\n",
      "Book_60 - 0.620176\n",
      "Book_61 - 0.353170\n",
      "Book_62 - 0.284158\n",
      "Book_63 - 0.523699\n",
      "Book_64 - 0.422645\n",
      "Book_65 - 0.467030\n",
      "Book_66 - 0.545196\n",
      "Book_67 - 0.219898\n",
      "Book_68 - 0.876985\n",
      "Book_69 - 0.753622\n",
      "Book_70 - 0.572372\n",
      "Book_71 - 0.430989\n",
      "Book_72 - 0.299745\n",
      "Book_73 - 0.411288\n",
      "Book_74 - 0.273323\n",
      "Book_75 - 0.178874\n",
      "Book_76 - 0.295110\n",
      "Book_77 - 0.642485\n",
      "Book_78 - 0.363831\n",
      "Book_79 - 0.818577\n",
      "Book_80 - 0.546587\n",
      "Book_81 - 0.162070\n",
      "Book_82 - 0.445475\n",
      "Book_83 - 0.320895\n",
      "Book_84 - 0.365454\n",
      "Book_85 - 0.291575\n",
      "Book_86 - 0.277263\n",
      "Book_87 - 0.444490\n",
      "Book_88 - 0.452718\n",
      "Book_89 - 0.436319\n",
      "Book_90 - 0.198111\n",
      "Book_91 - 0.394310\n",
      "Book_92 - 0.325125\n",
      "Book_93 - 0.627651\n",
      "Book_94 - 0.769904\n",
      "Book_95 - 0.483138\n",
      "Book_96 - 0.461351\n",
      "Book_97 - 0.270425\n",
      "Book_98 - 0.084598\n",
      "Book_99 - 0.356183\n",
      "Book_100 - 0.368641\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "print (\"Vocabulary Size Score:\")\n",
    "for tl in tokens_list:\n",
    "    print (\"Book_%d - %f\" %  (i, vocab_scorer(tl)))\n",
    "    i = i + 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Long-word score function\n",
    "\n",
    "This function is used for scoring the long-word vocabulary size of a text and normalizing the output from 0 to 1. \n",
    "We begin by grabbing a list of all unique words in a text and feed to this function. After that we keep the words that contain more than 6 letters (this is what we decided a long word to be) and then count them. Finally we divide the counted long-words with the total unique words of the text provided and thus calculate the long-word score. Because we divided the counted long-words with the total unique words of the book our result is already normalized between one and zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def long_word_scorer(text):\n",
    "    try:\n",
    "        sort_words = sorted(set(text))\n",
    "        count_long_words = 0\n",
    "        long_word_score = 0.0\n",
    "        for s in sort_words:\n",
    "            if len(s) > 6:\n",
    "                count_long_words = count_long_words + 1\n",
    "        long_word_score = count_long_words / len(set(text))\n",
    "        return long_word_score\n",
    "    except (TypeError):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the long-word score for all books in our list and print out the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Long-word Vocabulary Score:\n",
      "Book_0 - 0.298130\n",
      "Book_1 - 0.301609\n",
      "Book_2 - 0.490136\n",
      "Book_3 - 0.408906\n",
      "Book_4 - 0.326118\n",
      "Book_5 - 0.357566\n",
      "Book_6 - 0.459762\n",
      "Book_7 - 0.359431\n",
      "Book_8 - 0.413857\n",
      "Book_9 - 0.326698\n",
      "Book_10 - 0.404318\n",
      "Book_11 - 0.245212\n",
      "Book_12 - 0.347449\n",
      "Book_13 - 0.446957\n",
      "Book_14 - 0.517599\n",
      "Book_15 - 0.517912\n",
      "Book_16 - 0.309125\n",
      "Book_17 - 0.356877\n",
      "Book_18 - 0.352492\n",
      "Book_19 - 0.470639\n",
      "Book_20 - 0.537236\n",
      "Book_21 - 0.556090\n",
      "Book_22 - 0.318016\n",
      "Book_23 - 0.485019\n",
      "Book_24 - 0.478842\n",
      "Book_25 - 0.526664\n",
      "Book_26 - 0.558115\n",
      "Book_27 - 0.491663\n",
      "Book_28 - 0.475513\n",
      "Book_29 - 0.488405\n",
      "Book_30 - 0.352636\n",
      "Book_31 - 0.451759\n",
      "Book_32 - 0.440104\n",
      "Book_33 - 0.367876\n",
      "Book_34 - 0.570509\n",
      "Book_35 - 0.526992\n",
      "Book_36 - 0.658302\n",
      "Book_37 - 0.563413\n",
      "Book_38 - 0.459762\n",
      "Book_39 - 0.524748\n",
      "Book_40 - 0.575719\n",
      "Book_41 - 0.399330\n",
      "Book_42 - 0.394645\n",
      "Book_43 - 0.552639\n",
      "Book_44 - 0.411952\n",
      "Book_45 - 0.492905\n",
      "Book_46 - 0.447368\n",
      "Book_47 - 0.508400\n",
      "Book_48 - 0.491579\n",
      "Book_49 - 0.424149\n",
      "Book_50 - 0.466479\n",
      "Book_51 - 0.439542\n",
      "Book_52 - 0.540485\n",
      "Book_53 - 0.417601\n",
      "Book_54 - 0.441570\n",
      "Book_55 - 0.458925\n",
      "Book_56 - 0.426824\n",
      "Book_57 - 0.501127\n",
      "Book_58 - 0.523666\n",
      "Book_59 - 0.405286\n",
      "Book_60 - 0.470149\n",
      "Book_61 - 0.536177\n",
      "Book_62 - 0.497961\n",
      "Book_63 - 0.527993\n",
      "Book_64 - 0.523033\n",
      "Book_65 - 0.516005\n",
      "Book_66 - 0.562546\n",
      "Book_67 - 0.362846\n",
      "Book_68 - 0.641229\n",
      "Book_69 - 0.549054\n",
      "Book_70 - 0.478842\n",
      "Book_71 - 0.501076\n",
      "Book_72 - 0.513435\n",
      "Book_73 - 0.474359\n",
      "Book_74 - 0.454314\n",
      "Book_75 - 0.423712\n",
      "Book_76 - 0.495779\n",
      "Book_77 - 0.590729\n",
      "Book_78 - 0.602644\n",
      "Book_79 - 0.519643\n",
      "Book_80 - 0.554331\n",
      "Book_81 - 0.372900\n",
      "Book_82 - 0.599766\n",
      "Book_83 - 0.494583\n",
      "Book_84 - 0.516093\n",
      "Book_85 - 0.471582\n",
      "Book_86 - 0.454127\n",
      "Book_87 - 0.542041\n",
      "Book_88 - 0.518367\n",
      "Book_89 - 0.511952\n",
      "Book_90 - 0.417081\n",
      "Book_91 - 0.580309\n",
      "Book_92 - 0.539298\n",
      "Book_93 - 0.539420\n",
      "Book_94 - 0.514638\n",
      "Book_95 - 0.500959\n",
      "Book_96 - 0.483421\n",
      "Book_97 - 0.494536\n",
      "Book_98 - 0.383562\n",
      "Book_99 - 0.491134\n",
      "Book_100 - 0.495756\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "print (\"Long-word Vocabulary Score:\")\n",
    "for tl in tokens_list:\n",
    "        print (\"Book_%d - %f\" %  (i, long_word_scorer(tl)))\n",
    "        i = i + 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lexical diversity function\n",
    "\n",
    "This function was calculated on the previous homework. It is used to calculate the lexical (word) diversity of a text. In order to do so we first calculate the total word count of the provided text and then calculate the unique word count. Finally, the diversity score is generated by dividing the total word count with the unique vocabulary size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lexical_diversity(text):\n",
    "    word_count = len(text)\n",
    "    vocab_size = len(set(text))\n",
    "    diversity_score = word_count / vocab_size\n",
    "    return diversity_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization function\n",
    "\n",
    "because the calculated diversity score above is not between 1 and 0, normalization must be applied. This function attempts to normalize any count by dividing it with the max/total number of counts. This generates a number between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(count, total):\n",
    "    return  count / total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Text Difficulty function\n",
    "\n",
    "This function is used for calculating the difficulty of a provided text. In order to do so a combination of all the above functions is used after they have been equally weighted. In other words, the lexical diversity score is initially calculated and then normalized. After that the vocabulary score is calculated and then the long-word score is generated. Finally the text difficulty score is calculated by adding all the above scores and dividing by their count (3). This gives us a normalized final score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_dif_scorer(text):\n",
    "    try:\n",
    "        lex_div = lexical_diversity(text)\n",
    "        nlex_div = normalize(lex_div, len(text)+len(set(text)))\n",
    "        voc_scr = vocab_scorer(text)\n",
    "        lwd_scr = long_word_scorer(text)\n",
    "        txt_dif = nlex_div + voc_scr + lwd_scr / 3\n",
    "        if txt_dif > 1:\n",
    "            txt_dif = 1.0\n",
    "        return txt_dif\n",
    "    except (TypeError):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the text difficulty score for all books in our list and print out the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Difficulty Score:\n",
      "Book_0 - 0.214488\n",
      "Book_1 - 0.226963\n",
      "Book_2 - 0.466078\n",
      "Book_3 - 0.435760\n",
      "Book_4 - 0.232257\n",
      "Book_5 - 0.295647\n",
      "Book_6 - 0.231608\n",
      "Book_7 - 0.331723\n",
      "Book_8 - 0.327231\n",
      "Book_9 - 0.292562\n",
      "Book_10 - 0.194596\n",
      "Book_11 - 0.345167\n",
      "Book_12 - 0.417010\n",
      "Book_13 - 0.682168\n",
      "Book_14 - 0.859076\n",
      "Book_15 - 0.929689\n",
      "Book_16 - 0.227904\n",
      "Book_17 - 0.352977\n",
      "Book_18 - 0.390893\n",
      "Book_19 - 0.756919\n",
      "Book_20 - 1.004672\n",
      "Book_21 - 1.185416\n",
      "Book_22 - 0.233757\n",
      "Book_23 - 0.769013\n",
      "Book_24 - 0.732077\n",
      "Book_25 - 0.875362\n",
      "Book_26 - 1.177168\n",
      "Book_27 - 0.855526\n",
      "Book_28 - 0.500584\n",
      "Book_29 - 1.154800\n",
      "Book_30 - 0.340921\n",
      "Book_31 - 0.855725\n",
      "Book_32 - 0.882489\n",
      "Book_33 - 0.223728\n",
      "Book_34 - 0.892464\n",
      "Book_35 - 0.595465\n",
      "Book_36 - 1.212353\n",
      "Book_37 - 0.532894\n",
      "Book_38 - 0.231608\n",
      "Book_39 - 0.416284\n",
      "Book_40 - 0.878795\n",
      "Book_41 - 0.358115\n",
      "Book_42 - 0.281213\n",
      "Book_43 - 0.844219\n",
      "Book_44 - 0.210666\n",
      "Book_45 - 0.442148\n",
      "Book_46 - 0.211518\n",
      "Book_47 - 0.628324\n",
      "Book_48 - 0.583731\n",
      "Book_49 - 0.534550\n",
      "Book_50 - 0.444352\n",
      "Book_51 - 0.465842\n",
      "Book_52 - 0.519517\n",
      "Book_53 - 0.243015\n",
      "Book_54 - 0.407214\n",
      "Book_55 - 0.463492\n",
      "Book_56 - 0.402992\n",
      "Book_57 - 0.424283\n",
      "Book_58 - 0.577455\n",
      "Book_59 - 0.372056\n",
      "Book_60 - 0.776974\n",
      "Book_61 - 0.532043\n",
      "Book_62 - 0.450318\n",
      "Book_63 - 0.699796\n",
      "Book_64 - 0.597110\n",
      "Book_65 - 0.639143\n",
      "Book_66 - 0.732808\n",
      "Book_67 - 0.341089\n",
      "Book_68 - 1.090790\n",
      "Book_69 - 0.936711\n",
      "Book_70 - 0.732077\n",
      "Book_71 - 0.598136\n",
      "Book_72 - 0.471052\n",
      "Book_73 - 0.569537\n",
      "Book_74 - 0.424941\n",
      "Book_75 - 0.320393\n",
      "Book_76 - 0.460539\n",
      "Book_77 - 0.839476\n",
      "Book_78 - 0.564849\n",
      "Book_79 - 0.991854\n",
      "Book_80 - 0.731459\n",
      "Book_81 - 0.286689\n",
      "Book_82 - 0.645516\n",
      "Book_83 - 0.485918\n",
      "Book_84 - 0.537628\n",
      "Book_85 - 0.448944\n",
      "Book_86 - 0.428828\n",
      "Book_87 - 0.625288\n",
      "Book_88 - 0.625623\n",
      "Book_89 - 0.607091\n",
      "Book_90 - 0.337375\n",
      "Book_91 - 0.587875\n",
      "Book_92 - 0.505052\n",
      "Book_93 - 0.807543\n",
      "Book_94 - 0.941522\n",
      "Book_95 - 0.650231\n",
      "Book_96 - 0.622596\n",
      "Book_97 - 0.435471\n",
      "Book_98 - 0.212998\n",
      "Book_99 - 0.520041\n",
      "Book_100 - 0.534036\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "print (\"Text Difficulty Score:\")\n",
    "for tl in tokens_list:\n",
    "        print (\"Book_%d - %f\" %  (i, text_dif_scorer(tl)))\n",
    "        i = i + 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing our results with those of last weeks homework, we can see that the scores are vastly different.\n",
    "Lex Div - HW1  | Txt_Dif - HW2\n",
    "\n",
    "Texts  Lex_Div  Txt_Dif    Title\n",
    "Book_12  13      0.417   The Beacon Second Reader\n",
    "Book_13  20      0.682   The Child's World Third Reader\n",
    "Book_30  16      0.341   Sanders' Union Fourth Reader\n",
    "\n",
    "\n",
    "What stands out is the fact that the range of results is vastly different (lexical diversity 0~20 and text difficulty 0~1).\n",
    "Additionally, another phenomenon that stands out is that Book_12 has a higher text difficulty score than Book_30 even though Book_30 has a higher lexical diversity score. Book 13 has the highest lexical diversity and text difficulty scores as expected."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
